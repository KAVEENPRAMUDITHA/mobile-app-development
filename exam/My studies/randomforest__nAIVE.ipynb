{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f4704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955e99f",
   "metadata": {},
   "source": [
    " Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08ee57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset එකේ Shape (X): (1000, 20)\n",
      "Labels වල Shape (y): (1000,)\n",
      "පළමු data point 5: \n",
      "[[ 1.50859903 -3.73028866  0.43689498  1.52886631 -0.33556399  1.1896752\n",
      "   1.97491807 -1.81182794  4.20527076 -0.4674646  -1.53323401  1.45420001\n",
      "   0.89706105  0.66175565 -7.65313728  2.41300979  0.55147623 -1.67359752\n",
      "  -1.91476986 -0.64493562]\n",
      " [-1.08580885 -2.07107013 -1.23711982 -4.41129675  1.91304161 -1.05878344\n",
      "   1.74000928  0.44813873  1.24064995  3.74018634  2.9216194  -1.09344043\n",
      "  -3.1629392  -0.67545623  6.35256789  2.01985224 -1.34751678  3.7872604\n",
      "  -2.58337265  0.63659388]\n",
      " [ 1.13186375  2.47790303  0.8426801  -1.58249896 -1.77814095 -1.18339417\n",
      "   0.46116321 -0.78560728 -3.16772325  1.74729491  5.54961658  0.6900948\n",
      "  -6.21976183 -2.85330257  6.41685849  2.55201257  2.43679138  0.06466985\n",
      "   0.15792623  3.0733003 ]\n",
      " [-3.68235094 -1.78121809  3.23352297  0.42698838 -0.58290997 -0.38362193\n",
      "  -0.80180683  0.23460484  1.77819122  1.67097838 -2.19266559  0.258001\n",
      "   0.8421217   2.48232365 -0.51794627  4.00468909  0.5245864  -1.91871209\n",
      "  -0.24228372 -0.4200907 ]\n",
      " [-1.00979071 -0.18147557 -0.61661229 -0.23847508  0.78540732  0.37852486\n",
      "   6.22519922  0.47149018  2.32740857 -0.32413118 -0.71210465  0.62976968\n",
      "  -0.67375342  0.68612266 -3.72440595  2.93395039  5.1181109  -0.76574826\n",
      "   1.14217779 -1.50506397]]\n",
      "පළමු label 5: \n",
      "[1 2 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "# X = Features (අපේ දත්ත), y = Labels (අපේ target එක)\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,       # data points (rows) ගණන\n",
    "    n_features=20,        # මුළු features (columns) ගණන\n",
    "    n_informative=15,     # target එකට ඇත්තටම අදාළ features ගණන\n",
    "    n_redundant=2,        # වෙනත් features වලින්ම හැදුණු features\n",
    "    n_classes=3,          # target classes ගණන (උදා: 0, 1, 2)\n",
    "    random_state=42       # ප්‍රතිඵල නැවත generate කරගැනීමට හැකිවීමට\n",
    ")\n",
    "\n",
    "print(f\"Dataset එකේ Shape (X): {X.shape}\")\n",
    "print(f\"Labels වල Shape (y): {y.shape}\")\n",
    "print(f\"පළමු data point 5: \\n{X[:5]}\")\n",
    "print(f\"පළමු label 5: \\n{y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc13e8",
   "metadata": {},
   "source": [
    "Data split into test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b9f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (X_train) shape: (700, 20)\n",
      "Testing data (X_test) shape: (300, 20)\n"
     ]
    }
   ],
   "source": [
    "# දත්ත 70% (train) සහ 30% (test) ලෙස වෙන් කිරීම\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30,  # 30%ක් test කිරීම සඳහා වෙන් කරයි\n",
    "    random_state=42,\n",
    "    stratify=y      # classes 3ම train/test දෙකේම සමබරව බෙදීමට\n",
    ")\n",
    "\n",
    "print(f\"Training data (X_train) shape: {X_train.shape}\")\n",
    "print(f\"Testing data (X_test) shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff432fcd",
   "metadata": {},
   "source": [
    "Random Forest Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d93e203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starting...\n",
      "Model training complete. ✅\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# අපි trees 100ක් භාවිතා කරමු\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100, #(Forest) තිබිය යුතු Decision Trees ගණනයි\n",
    "    random_state=42,\n",
    "    n_jobs=-1         # CPU එකේ සියලුම cores training සඳහා යොදාගන්න\n",
    ")\n",
    "\n",
    "# 2. Model එක train කිරීම\n",
    "print(\"Model training starting...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Model training complete. ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683e96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 74.33%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76        99\n",
      "           1       0.69      0.76      0.72        99\n",
      "           2       0.78      0.73      0.75       102\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.75      0.74      0.74       300\n",
      "weighted avg       0.75      0.74      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Test data සඳහා predictions ගැනීම\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Accuracy එක ගණනය කිරීම\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 3. වඩාත් විස්තරාත්මක report එකක් (Precision, Recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ba196",
   "metadata": {},
   "source": [
    "වැදගත්ම Features බැලීම (Feature Importance)\n",
    "\n",
    "Random Forest වල ඇති විශාල වාසියක් නම්, අපේ target එක (y) predict කිරීමට වඩාත්ම දායක වූ features මොනවාදැයි බලාගැනීමට හැකි වීමයි."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4610abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Importance Top 10 ---\n",
      "1. Feature 0: 0.0957\n",
      "2. Feature 3: 0.0805\n",
      "3. Feature 10: 0.0696\n",
      "4. Feature 13: 0.0607\n",
      "5. Feature 16: 0.0566\n",
      "6. Feature 14: 0.0519\n",
      "7. Feature 6: 0.0507\n",
      "8. Feature 19: 0.0495\n",
      "9. Feature 1: 0.0478\n",
      "10. Feature 12: 0.0476\n"
     ]
    }
   ],
   "source": [
    "# Model එකෙන් feature importances ලබාගැනීම\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "# Features වල නම් (අපිට නම් නැති නිසා 0, 1, 2... ලෙස ගනිමු)\n",
    "feature_names = [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# වැදගත්කම අනුව sort කිරීම\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"\\n--- Feature Importance Top 10 ---\")\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556819c",
   "metadata": {},
   "source": [
    "**Naive Bayes** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e8fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes model training starting...\n",
      "Naive Bayes model training complete. ✅\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 1. Model එක නිර්මාණය කිරීම (Initialize)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# 2. Model එක train කිරීම\n",
    "print(\"Naive Bayes model training starting...\")\n",
    "# Naive Bayes හුදෙක් එක් එක් class එක සඳහා features වල mean සහ variance ගණනය කරයි\n",
    "nb_model.fit(X_train, y_train)\n",
    "print(\"Naive Bayes model training complete. ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9eb134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Model Accuracy: 74.33%\n",
      "\n",
      "Classification Report (Naive Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76        99\n",
      "           1       0.69      0.76      0.72        99\n",
      "           2       0.78      0.73      0.75       102\n",
      "\n",
      "    accuracy                           0.74       300\n",
      "   macro avg       0.75      0.74      0.74       300\n",
      "weighted avg       0.75      0.74      0.74       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_naive = rf_model.predict(X_test)\n",
    "accuracy_nb= accuracy_score(y_test, y_pred_naive)\n",
    "print(f\"\\nNaive Bayes Model Accuracy: {accuracy_nb * 100:.2f}%\")\n",
    "\n",
    "# 3. විස්තරාත්මක report එක\n",
    "print(\"\\nClassification Report (Naive Bayes):\")\n",
    "print(classification_report(y_test, y_pred_naive))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d420fbf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bdd14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text Data:\n",
      "['offer free prize claim now', 'call now for free prize', 'buy cheap medicine online', 'hello how are you today', 'lets schedule the project meeting', 'see you tomorrow']\n",
      "Labels: [1 1 1 0 0 0]\n",
      "\n",
      "--- Training MultinomialNB (Counts) ---\n",
      "MultinomialNB Model Trained. ✅\n",
      "\n",
      "--- Training BernoulliNB (Presence/Absence) ---\n",
      "BernoulliNB Model Trained. ✅\n",
      "\n",
      "--- Testing Models ---\n",
      "Test Data: ['claim your free prize now', 'project meeting is today']\n",
      "MultinomialNB Prediction (1=Spam, 0=Not Spam): [1 0]\n",
      "BernoulliNB Prediction (1=Spam, 0=Not Spam):   [1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# --- 1. අපේ Sample Data (Text) ---\n",
    "# සරල ඊමේල් හෝ වාක්‍ය 6ක්\n",
    "documents = [\n",
    "    \"offer free prize claim now\",       # Spam\n",
    "    \"call now for free prize\",          # Spam\n",
    "    \"buy cheap medicine online\",        # Spam\n",
    "    \"hello how are you today\",          # Not Spam\n",
    "    \"lets schedule the project meeting\",# Not Spam\n",
    "    \"see you tomorrow\"                  # Not Spam\n",
    "]\n",
    "\n",
    "# අදාළ Labels (1 = Spam, 0 = Not Spam)\n",
    "labels = np.array([1, 1, 1, 0, 0, 0])\n",
    "\n",
    "print(\"Original Text Data:\")\n",
    "print(documents)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "# --- 2. Multinomial Naive Bayes (Counts මත පදනම්ව) ---\n",
    "print(\"\\n--- Training MultinomialNB (Counts) ---\")\n",
    "\n",
    "# 2.1 Vectorizer එක සෑදීම (වචන ගණන් කිරීමට)\n",
    "# මෙය 'offer' 1, 'free' 1, 'prize' 1, 'claim' 1, 'now' 1 ලෙස ගණන් කරයි\n",
    "mnb_vectorizer = CountVectorizer()\n",
    "\n",
    "# 2.2 Text දත්ත Numbers (Counts) බවට පත්කිරීම\n",
    "X_train_counts = mnb_vectorizer.fit_transform(documents)\n",
    "\n",
    "# (බලාගැනීමට)\n",
    "# print(\"Count Matrix (Multinomial):\\n\", X_train_counts.toarray())\n",
    "# print(\"Features (Words):\", mnb_vectorizer.get_feature_names_out())\n",
    "\n",
    "# 2.3 MultinomialNB model එක Train කිරීම\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train_counts, labels)\n",
    "print(\"MultinomialNB Model Trained. ✅\")\n",
    "\n",
    "\n",
    "# --- 3. Bernoulli Naive Bayes (Presence/Absence මත පදනම්ව) ---\n",
    "print(\"\\n--- Training BernoulliNB (Presence/Absence) ---\")\n",
    "\n",
    "# 3.1 Vectorizer එක සෑදීම (binary=True ලෙස යොදා)\n",
    "# මෙය 'offer' 1, 'free' 1, 'prize' 1, 'claim' 1, 'now' 1 ලෙස ගණන් කරයි\n",
    "# වචනයක් 5 පාරක් තිබුණත් \"1\" ලෙසයි ගන්නේ\n",
    "bnb_vectorizer = CountVectorizer(binary=True) \n",
    "\n",
    "# 3.2 Text දත්ත Numbers (Binary) බවට පත්කිරීම\n",
    "X_train_binary = bnb_vectorizer.fit_transform(documents)\n",
    "\n",
    "# (බලාගැනීමට)\n",
    "# print(\"Binary Matrix (Bernoulli):\\n\", X_train_binary.toarray())\n",
    "# print(\"Features (Words):\", bnb_vectorizer.get_feature_names_out())\n",
    "\n",
    "# 3.3 BernoulliNB model එක Train කිරීම\n",
    "bnb_model = BernoulliNB()\n",
    "bnb_model.fit(X_train_binary, labels)\n",
    "print(\"BernoulliNB Model Trained. ✅\")\n",
    "\n",
    "\n",
    "# --- 4. Models දෙකම Test කිරීම ---\n",
    "print(\"\\n--- Testing Models ---\")\n",
    "# අලුත් ඊමේල් 2ක්\n",
    "test_data = [\n",
    "    \"claim your free prize now\",  # Spam විය යුතුයි\n",
    "    \"project meeting is today\"    # Not Spam විය යුතුයි\n",
    "]\n",
    "\n",
    "print(f\"Test Data: {test_data}\")\n",
    "\n",
    "# 4.1 Multinomial Prediction\n",
    "# test data එකත් 'count' vectorizer එකෙන්ම transform කළ යුතුයි\n",
    "X_test_counts = mnb_vectorizer.transform(test_data)\n",
    "mnb_prediction = mnb_model.predict(X_test_counts)\n",
    "print(f\"MultinomialNB Prediction (1=Spam, 0=Not Spam): {mnb_prediction}\")\n",
    "\n",
    "# 4.2 Bernoulli Prediction\n",
    "# test data එකත් 'binary' vectorizer එකෙන්ම transform කළ යුතුයි\n",
    "X_test_binary = bnb_vectorizer.transform(test_data)\n",
    "bnb_prediction = bnb_model.predict(X_test_binary)\n",
    "print(f\"BernoulliNB Prediction (1=Spam, 0=Not Spam):   {bnb_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675d22d",
   "metadata": {},
   "source": [
    "``Gaussian Naive Bayes ``(අඛණ්ඩ දත්ත, continuous data, සඳහා) වගේ නෙවෙයි, මේ දෙකම ප්‍රධාන වශයෙන් භාවිතා වෙන්නේ විවික්ත දත්ත (discrete data) සඳහා, විශේෂයෙන්ම Text Classification (ලිපි, ඊමේල්, tweets වැනි දේ වර්ග කිරීම) සඳහායි.\n",
    "\n",
    "මේ දෙකේ ප්‍රධාන වෙනස තියෙන්නේ දත්ත දිහා බලන විදිහේ.\n",
    "\n",
    "**1. Multinomial Naive Bayes (MNB)**\n",
    "\n",
    "මේක \"Count\" (වාර ගණන) මත පදනම් වූ model එකක්.\n",
    "\n",
    "භාවිතා කරන්නේ කුමන දත්ත සඳහාද?: \"වාර ගණන\" (frequencies) හෝ \"ගණන්\" (counts) නිරූපණය කරන දත්ත සඳහා.\n",
    "\n",
    "ප්‍රධාන අදහස: එය බලන්නේ යම් class එකකට අදාළව එක් එක් feature එක කී වතාවක් (how many times) හමු වෙනවාද කියලයි.\n",
    "\n",
    "හොඳම උදාහරණය: Text Classification (Spam Email හඳුනාගැනීම)\n",
    "\n",
    "MNB model එක train කරන විට, එය මෙසේ ගණනය කරනවා:\n",
    "\n",
    "\"Spam\" ලෙස ලේබල් වූ ඊමේල් වල \"offer\" කියන වචනය 50 වතාවක් හමුවුණා.\n",
    "\n",
    "\"Spam\" වල \"free\" කියන වචනය 75 වතාවක් හමුවුණා.\n",
    "\n",
    "\"Not Spam\" ඊමේල් වල \"offer\" වචනය 2 වතාවක් හමුවුණා.\n",
    "\n",
    "අලුත් ඊමේල් එකක් ආවම, MNB එක බලන්නේ ඒකෙත් \"offer\" වචනය 3 පාරක්, \"free\" වචනය 2 පාරක් තියෙනවා වගේ count එක දිහායි.\n",
    "\n",
    "ඒ වාර ගණන (counts) අනුව, අලුත් ඊමේල් එක \"Spam\" වෙන්න තියෙන සම්භාවිතාව ගණනය කරනවා.\n",
    "\n",
    "කෙටියෙන්: MNB වැදගත් වෙන්නේ feature එක කී පාරක් ආවද කියන එකටයි.\n",
    "\n",
    "**2. Bernoulli Naive Bayes (BNB)**\n",
    "\n",
    "මේක \"Presence\" (තිබේද/නැද්ද) මත පදනම් වූ model එකක්.\n",
    "\n",
    "භාවිතා කරන්නේ කුමන දත්ත සඳහාද?: \"ද්විමය\" (Binary) දත්ත සඳහා. එනම්, feature එක \"තිබෙනවා\" (1) හෝ \"නැහැ\" (0) යන්න පමණයි.\n",
    "\n",
    "ප්‍රධාන අදහස: එය බලන්නේ යම් class එකකට අදාළව එක් එක් feature එක තිබෙනවාද, නැද්ද (present or absent) යන්න පමණයි. කී වතාවක් තිබුණත් ගණන් ගන්නේ නැහැ.\n",
    "\n",
    "හොඳම උදාහරණය: Text Classification (එකම Spam උදාහරණය)\n",
    "\n",
    "BNB model එක train කරන විට, එය මෙසේ ගණනය කරනවා:\n",
    "\n",
    "\"Spam\" ඊමේල් 100න් 80කම \"offer\" කියන වචනය (අඩුම තරමේ එක පාරක්වත්) තිබුණා.\n",
    "\n",
    "\"Spam\" ඊමේල් 100න් 90කම \"free\" කියන වචනය තිබුණා.\n",
    "\n",
    "\"Not Spam\" ඊමේල් 100න් 5ක විතරයි \"offer\" වචනය තිබුණේ.\n",
    "\n",
    "අලුත් ඊමේල් එකක් ආවම, BNB එක බලන්නේ \"offer\" වචනය තියෙනවද (1) නැද්ද (0)? කියන එක විතරයි. ඒක 5 පාරක් තිබුණත්, 1 පාරක් තිබුණත් BNB එකට ඒක \"1\" (present) විතරයි.\n",
    "\n",
    "ඒ තිබේද/නැද්ද (presence/absence) අනුව, අලුත් ඊමේල් එක \"Spam\" වෙන්න තියෙන සම්භාවිතාව ගණනය කරනවා.\n",
    "\n",
    "කෙටියෙන්: BNB වැදගත් වෙන්නේ feature එක තියෙනවද, නැද්ද කියන එකටයි."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent_systems_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
