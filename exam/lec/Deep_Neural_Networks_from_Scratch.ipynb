{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Networks from Scratch\n",
        "\n",
        "## Introduction\n",
        "This tutorial teaches you to build deep neural networks from scratch using only NumPy. By the end, you'll understand how neural networks work at the lowest level.\n",
        "\n",
        "## Prerequisites\n",
        "- Basic Python knowledge\n",
        "- Understanding of matrices and derivatives (calculus)\n",
        "- Jupyter notebook environment"
      ],
      "metadata": {
        "id": "TiTqrN8aavcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setting Up and Understanding the Data\n",
        "\n",
        "### Cell 1: Import Libraries"
      ],
      "metadata": {
        "id": "bC2KREm4a-Pt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOXirindauGz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Import NumPy for numerical computations and matrix operations\n",
        "- Line 2: Import matplotlib for visualizing our data and results"
      ],
      "metadata": {
        "id": "A67WXgnmbKmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 2: Set Random Seed"
      ],
      "metadata": {
        "id": "XvC4B05ybS82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "3zH1V-y0_uCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: 2x3 array\n",
        "random_array = np.random.rand(2, 3)\n",
        "print(random_array)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvTR1P-kABBB",
        "outputId": "0135f898-6995-445c-894c-c3da2a04baf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.53182759 0.63440096 0.84943179]\n",
            " [0.72445532 0.61102351 0.72244338]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "# Generate a 2x4 array of random integers between 0 (inclusive) and 10 (exclusive)\n",
        "seeded_random_array = np.random.randint(0, 10, size=(2, 4))\n",
        "\n",
        "print(seeded_random_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktomHLToAz8P",
        "outputId": "92d9e7fb-d216-490e-ab62-f8cabbc34950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 2 6 1]\n",
            " [3 9 6 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Set random seed to ensure reproducible results across different runs"
      ],
      "metadata": {
        "id": "dhk1cbBTbZnj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 3: Create Simple Dataset"
      ],
      "metadata": {
        "id": "YCrGOoXvbeir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])"
      ],
      "metadata": {
        "id": "_k6NGqr0bjt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Create input data X with 4 samples, each having 2 features (XOR problem)\n",
        "- Line 2: Create target labels y - this is the XOR truth table (output is 1 when inputs differ)"
      ],
      "metadata": {
        "id": "j00sk2W2bquT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 4: Examine Data Shape"
      ],
      "metadata": {
        "id": "k5eXgWr4bzOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input shape: {X.shape}\")\n",
        "print(f\"Output shape: {y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVowAD47b21y",
        "outputId": "188118ca-4b30-4dc7-92bc-92ccc0c38685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (4, 2)\n",
            "Output shape: (4, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Print the shape of input data (4 samples × 2 features)\n",
        "- Line 2: Print the shape of output data (4 samples × 1 output)"
      ],
      "metadata": {
        "id": "UJFZ1lP7b8Oy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 5: Visualize the Data"
      ],
      "metadata": {
        "id": "a4tlbJRTcAxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y.ravel(), cmap='viridis', s=100)\n",
        "plt.title(\"XOR Problem Dataset\")\n",
        "plt.xlabel(\"Feature 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Zu-NL071cKEd",
        "outputId": "41315b67-b805-466c-d535-898a44a299bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Feature 1')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Create scatter plot where colors represent different classes (0=dark, 1=bright)\n",
        "- Line 2: Add title to explain this is the XOR problem\n",
        "- Line 3: Label the x-axis as Feature 1"
      ],
      "metadata": {
        "id": "MjE3NVMXccAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Activation Functions"
      ],
      "metadata": {
        "id": "e_kp2BOXcn-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 6: Define Sigmoid Function"
      ],
      "metadata": {
        "id": "6BcrN-nZcowj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "wFXyZAoucjJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Define function that takes any real number and squashes it between 0 and 1\n",
        "- Line 2: This is the mathematical formula: σ(x) = 1/(1+e^(-x))"
      ],
      "metadata": {
        "id": "VDmKgfslc1ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 7: Define Sigmoid Derivative"
      ],
      "metadata": {
        "id": "UNjUPVYLc-sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))"
      ],
      "metadata": {
        "id": "d5vzx7Edc0aV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Define the derivative of sigmoid function (needed for backpropagation)\n",
        "- Line 2: Mathematical property: σ'(x) = σ(x) × (1 - σ(x))"
      ],
      "metadata": {
        "id": "ir9tla_5dHI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 8: Test Activation Functions"
      ],
      "metadata": {
        "id": "iJyRS2QLdNSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_values = np.array([-2, -1, 0, 1, 2])\n",
        "print(f\"Sigmoid: {sigmoid(test_values)}\")\n",
        "print(f\"Derivative: {sigmoid_derivative(test_values)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tuc82kXdIhN",
        "outputId": "6ce73a61-cb51-48ea-a1f7-ef9ec810ca27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid: [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
            "Derivative: [0.10499359 0.19661193 0.25       0.19661193 0.10499359]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Create test values to see how our functions behave\n",
        "- Line 2: Print sigmoid outputs (should be between 0 and 1)\n",
        "- Line 3: Print derivative values (should be positive). x=0 Has the Maximum Derivative. it measures how steeply the sigmoid curve is changing at each point.\n",
        "\n",
        "At x = 0:\n",
        "\n",
        "σ(0) = 0.5\n",
        "σ'(0) = 0.5 × (1 - 0.5) = 0.5 × 0.5 = 0.25\n",
        "Maximum because both factors are equal and maximized\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1V2jy3ugdYqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Neural Network Architecture"
      ],
      "metadata": {
        "id": "M3XZLT6rdcjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 9: Define Network Parameters"
      ],
      "metadata": {
        "id": "MpWS6VpsdfEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1"
      ],
      "metadata": {
        "id": "cp3jAgijdiLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Number of input features (2 for our XOR problem)\n",
        "- Line 2: Number of neurons in hidden layer (3 should be enough for XOR)\n",
        "- Line 3: Number of output neurons (1 for binary classification)"
      ],
      "metadata": {
        "id": "MZqDIMrSdmUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 10: Initialize Weights for Input to Hidden Layer"
      ],
      "metadata": {
        "id": "wY2bKgXSdqKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = np.random.randn(input_size, hidden_size) * 0.5\n",
        "b1 = np.zeros((1, hidden_size))"
      ],
      "metadata": {
        "id": "2tt8drLfdsvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Create weight matrix connecting inputs to hidden layer (2×3), scaled by 0.5\n",
        "- Line 2: Initialize biases for hidden layer to zero (1×3)"
      ],
      "metadata": {
        "id": "DjO0C3ardznv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 11: Initialize Weights for Hidden to Output Layer"
      ],
      "metadata": {
        "id": "kn0oOLUwd7UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = np.random.randn(hidden_size, output_size) * 0.5\n",
        "b2 = np.zeros((1, output_size))"
      ],
      "metadata": {
        "id": "j-Z9wirCd-X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Create weight matrix connecting hidden to output layer (3×1), scaled by 0.5\n",
        "- Line 2: Initialize bias for output layer to zero (1×1)"
      ],
      "metadata": {
        "id": "vUCPGXe8eCwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 12: Check Weight Shapes"
      ],
      "metadata": {
        "id": "MBEOD2_0eGwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"W1 shape: {W1.shape}, b1 shape: {b1.shape}\")\n",
        "print(f\"W2 shape: {W2.shape}, b2 shape: {b2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7DAvZEEeJz_",
        "outputId": "6cb9328a-1b9c-4bb2-839e-cbab94e5f1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1 shape: (2, 3), b1 shape: (1, 3)\n",
            "W2 shape: (3, 1), b2 shape: (1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Verify shapes of first layer weights and biases\n",
        "- Line 2: Verify shapes of second layer weights and biases"
      ],
      "metadata": {
        "id": "eWYqqm7xeO9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Forward Propagation"
      ],
      "metadata": {
        "id": "sqv5GvoCeSfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 13: Forward Pass - Hidden Layer"
      ],
      "metadata": {
        "id": "iw_uxkfxeVZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = np.dot(X, W1) + b1\n",
        "a1 = sigmoid(z1)"
      ],
      "metadata": {
        "id": "YvUy-QpfeZCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Compute linear combination: z1 = X·W1 + b1 (before activation)\n",
        "- Line 2: Apply sigmoid activation to get hidden layer outputs"
      ],
      "metadata": {
        "id": "6NSXC3Qted-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 14: Forward Pass - Output Layer"
      ],
      "metadata": {
        "id": "wZNXBzxbehJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z2 = np.dot(a1, W2) + b2\n",
        "a2 = sigmoid(z2)"
      ],
      "metadata": {
        "id": "-CqINkvseoVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Compute linear combination for output layer: z2 = a1·W2 + b2\n",
        "- Line 2: Apply sigmoid to get final predictions (between 0 and 1)"
      ],
      "metadata": {
        "id": "6xsC0ux5ett9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 15: Check Forward Pass Results"
      ],
      "metadata": {
        "id": "hU8EmyiWey8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Hidden layer output shape: {a1.shape}\")\n",
        "print(f\"Final predictions: {a2.ravel()}\")\n",
        "print(f\"Target values: {y.ravel()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZW9VhDQe26e",
        "outputId": "81749cb8-973d-4f32-919f-df206d313161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layer output shape: (4, 3)\n",
            "Final predictions: [0.61521647 0.64757458 0.62071863 0.65098344]\n",
            "Target values: [0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Verify hidden layer produces correct shape (4×3)\n",
        "- Line 2: Show current predictions (probably random since weights are random)\n",
        "- Line 3: Show what we want the network to learn"
      ],
      "metadata": {
        "id": "m6Vjho7Ke8fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Cost Function"
      ],
      "metadata": {
        "id": "oZTednRVfBDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 16: Define Mean Squared Error"
      ],
      "metadata": {
        "id": "yFltz5dEfEWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(predictions, targets):\n",
        "    return np.mean((predictions - targets) ** 2)"
      ],
      "metadata": {
        "id": "zCGvoDJffG9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Define function that calculates how far our predictions are from targets\n",
        "- Line 2: MSE formula: average of squared differences between predictions and actual values"
      ],
      "metadata": {
        "id": "CVKkMrRKfO4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 17: Calculate Initial Cost"
      ],
      "metadata": {
        "id": "vmq4buA8fTEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_cost = compute_cost(a2, y)\n",
        "print(f\"Initial cost: {initial_cost:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j5WXb0CfVqb",
        "outputId": "b2ac7889-4b9b-4843-9299-1c82938ff413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial cost: 0.2676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Calculate cost with random weights (should be high)\n",
        "- Line 2: Print the cost - this should decrease as we train"
      ],
      "metadata": {
        "id": "se5bPZsYfeLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Backpropagation"
      ],
      "metadata": {
        "id": "6Y2u5q69fhDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_output = a2 - y\n",
        "delta_output = error_output * sigmoid_derivative(z2)"
      ],
      "metadata": {
        "id": "sDlHCKpbfkOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Calculate how much our output is wrong (prediction - actual)\n",
        "- Line 2: Multiply error by derivative to get gradient for output layer"
      ],
      "metadata": {
        "id": "xzpCHv2Gfo1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 19: Hidden Layer Error (Backpropagation)"
      ],
      "metadata": {
        "id": "x8P1PLPJftDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_hidden = np.dot(delta_output, W2.T)\n",
        "delta_hidden = error_hidden * sigmoid_derivative(z1)"
      ],
      "metadata": {
        "id": "uF5OTWijfvhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Propagate error backwards using weights (chain rule of calculus)\n",
        "- Line 2: Apply derivative of activation function to get hidden layer gradients"
      ],
      "metadata": {
        "id": "emADQNa2h9a5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 20: Calculate Weight Gradients"
      ],
      "metadata": {
        "id": "NJi5jh1Upvt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW2 = np.dot(a1.T, delta_output) / X.shape[0]\n",
        "db2 = np.mean(delta_output, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "0QEQXO1DpwZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Calculate gradient for output weights (average over all samples)\n",
        "- Line 2: Calculate gradient for output bias (average of deltas)"
      ],
      "metadata": {
        "id": "JUjNzOZ7pz5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 21: Calculate More Weight Gradients"
      ],
      "metadata": {
        "id": "S9GEHid9p5Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dW1 = np.dot(X.T, delta_hidden) / X.shape[0]\n",
        "db1 = np.mean(delta_hidden, axis=0, keepdims=True)"
      ],
      "metadata": {
        "id": "fpl-4j45p7ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Calculate gradient for hidden weights (how much to change W1)\n",
        "- Line 2: Calculate gradient for hidden bias (how much to change b1)"
      ],
      "metadata": {
        "id": "b8XcPUVmp95d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Parameter Updates"
      ],
      "metadata": {
        "id": "9eJ8h5AlqDAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 22: Set Learning Rate"
      ],
      "metadata": {
        "id": "n9XvKkDnqF2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1.0"
      ],
      "metadata": {
        "id": "lMruAVAHqIuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: How big steps we take when updating weights (1.0 is quite large but works for this simple problem)\n"
      ],
      "metadata": {
        "id": "oeLTruzvqLKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 23: Update Output Layer Parameters"
      ],
      "metadata": {
        "id": "d1ZUhftBqNab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = W2 - learning_rate * dW2\n",
        "b2 = b2 - learning_rate * db2"
      ],
      "metadata": {
        "id": "FfDccc1WqPgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Update output weights by moving in opposite direction of gradient\n",
        "- Line 2: Update output bias using its gradient"
      ],
      "metadata": {
        "id": "qgdJODHBqRtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 24: Update Hidden Layer Parameters"
      ],
      "metadata": {
        "id": "PQaB0cJIqUoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = W1 - learning_rate * dW1\n",
        "b1 = b1 - learning_rate * db1"
      ],
      "metadata": {
        "id": "ctcDO7EUqWrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Update hidden weights to reduce cost\n",
        "- Line 2: Update hidden bias to reduce cost"
      ],
      "metadata": {
        "id": "P74Yz84ytwKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Complete Training Function"
      ],
      "metadata": {
        "id": "ew__rJ02ty5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 25: Define Training Function"
      ],
      "metadata": {
        "id": "RVGvYTljt0or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(X, y, epochs):\n",
        "    costs = []\n",
        "    return costs"
      ],
      "metadata": {
        "id": "hGAIEo0Wt3Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "- Line 1: Function that will train our network for specified number of epochs\n",
        "- Line 2: List to store cost at each epoch for plotting\n",
        "- Line 3: Return costs for analysis"
      ],
      "metadata": {
        "id": "US2YYoQrt538"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cell 26: Training Loop Setup\n",
        "```python\n",
        "def full_training(X, y, epochs=1000):\n",
        "    global W1, b1, W2, b2\n",
        "    costs = []\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Define complete training function with default 1000 epochs\n",
        "- Line 2: Declare we'll modify global weight variables\n",
        "- Line 3: Initialize list to track cost over time\n",
        "\n",
        "### Cell 27: Single Epoch Training\n",
        "```python\n",
        "    for epoch in range(epochs):\n",
        "        # Forward pass\n",
        "        z1 = np.dot(X, W1) + b1\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Loop through specified number of training iterations\n",
        "- Line 2: Comment explaining we start with forward pass\n",
        "- Line 3: Compute hidden layer input (linear combination)\n",
        "\n",
        "### Cell 28: Complete Forward Pass in Loop\n",
        "```python\n",
        "        a1 = sigmoid(z1)\n",
        "        z2 = np.dot(a1, W2) + b2\n",
        "        a2 = sigmoid(z2)\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Apply activation to get hidden layer output\n",
        "- Line 2: Compute output layer input\n",
        "- Line 3: Apply final activation to get predictions\n",
        "\n",
        "### Cell 29: Compute Cost in Loop\n",
        "```python\n",
        "        cost = compute_cost(a2, y)\n",
        "        costs.append(cost)\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Calculate current cost (how wrong our predictions are)\n",
        "- Line 2: Store cost for later plotting\n",
        "\n",
        "### Cell 30: Backpropagation in Loop\n",
        "```python\n",
        "        error_output = a2 - y\n",
        "        delta_output = error_output * sigmoid_derivative(z2)\n",
        "        error_hidden = np.dot(delta_output, W2.T)\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Calculate output layer error\n",
        "- Line 2: Apply chain rule for output layer gradient\n",
        "- Line 3: Propagate error back to hidden layer\n",
        "\n",
        "### Cell 31: Hidden Layer Gradients\n",
        "```python\n",
        "        delta_hidden = error_hidden * sigmoid_derivative(z1)\n",
        "        dW2 = np.dot(a1.T, delta_output) / X.shape[0]\n",
        "        db2 = np.mean(delta_output, axis=0, keepdims=True)\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Calculate hidden layer gradients using chain rule\n",
        "- Line 2: Compute gradient for output layer weights\n",
        "- Line 3: Compute gradient for output layer bias\n",
        "\n",
        "### Cell 32: Remaining Gradients and Updates\n",
        "```python\n",
        "        dW1 = np.dot(X.T, delta_hidden) / X.shape[0]\n",
        "        db1 = np.mean(delta_hidden, axis=0, keepdims=True)\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Compute gradient for hidden layer weights\n",
        "- Line 2: Compute gradient for hidden layer bias\n",
        "\n",
        "### Cell 33: Parameter Updates in Loop\n",
        "```python\n",
        "        W2 = W2 - learning_rate * dW2\n",
        "        b2 = b2 - learning_rate * db2\n",
        "        W1 = W1 - learning_rate * dW1\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Update output layer weights (gradient descent step)\n",
        "- Line 2: Update output layer bias\n",
        "- Line 3: Update hidden layer weights\n",
        "\n",
        "### Cell 34: Final Update and Return\n",
        "```python\n",
        "        b1 = b1 - learning_rate * db1\n",
        "        \n",
        "    return costs\n",
        "```\n",
        "**Explanation:**\n",
        "- Line 1: Update hidden layer bias\n",
        "- Line 2: Empty line for readability\n",
        "- Line 3: Return list of costs for analysis"
      ],
      "metadata": {
        "id": "eo8QRNqkY3v9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Update and Return"
      ],
      "metadata": {
        "id": "vVQwuoJxIWSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_training(X, y, epochs=1000):\n",
        "    \"\"\"\n",
        "    Complete training function for the neural network\n",
        "\n",
        "    Args:\n",
        "        X: Input data\n",
        "        y: Target outputs\n",
        "        epochs: Number of training iterations\n",
        "\n",
        "    Returns:\n",
        "        costs: List of costs at each epoch\n",
        "    \"\"\"\n",
        "    global W1, b1, W2, b2\n",
        "    costs = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Forward Pass\n",
        "        z1 = np.dot(X, W1) + b1          # Hidden layer input\n",
        "        a1 = sigmoid(z1)                 # Hidden layer output\n",
        "        z2 = np.dot(a1, W2) + b2         # Output layer input\n",
        "        a2 = sigmoid(z2)                 # Final predictions\n",
        "\n",
        "        # Calculate and store cost\n",
        "        cost = compute_cost(a2, y)\n",
        "        costs.append(cost)\n",
        "\n",
        "        # Backward Pass (Backpropagation)\n",
        "        error_output = a2 - y                              # Output error\n",
        "        delta_output = error_output * sigmoid_derivative(z2) # Output delta\n",
        "\n",
        "        error_hidden = np.dot(delta_output, W2.T)          # Hidden error\n",
        "        delta_hidden = error_hidden * sigmoid_derivative(z1) # Hidden delta\n",
        "\n",
        "        # Calculate gradients\n",
        "        dW2 = np.dot(a1.T, delta_output) / X.shape[0]      # Output weights gradient\n",
        "        db2 = np.mean(delta_output, axis=0, keepdims=True)  # Output bias gradient\n",
        "        dW1 = np.dot(X.T, delta_hidden) / X.shape[0]       # Hidden weights gradient\n",
        "        db1 = np.mean(delta_hidden, axis=0, keepdims=True)  # Hidden bias gradient\n",
        "\n",
        "        # Update parameters (Gradient Descent)\n",
        "        W2 = W2 - learning_rate * dW2\n",
        "        b2 = b2 - learning_rate * db2\n",
        "        W1 = W1 - learning_rate * dW1\n",
        "        b1 = b1 - learning_rate * db1\n",
        "\n",
        "        # Print progress every 500 epochs\n",
        "        if epoch % 500 == 0:\n",
        "            print(f\"Epoch {epoch}, Cost: {cost:.6f}\")\n",
        "\n",
        "    return costs"
      ],
      "metadata": {
        "id": "tCWdWusVZXo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-D9PZMRspl2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PART 6: PREDICTION FUNCTION =====\n",
        "\n",
        "def predict(X_test):\n",
        "    \"\"\"Make predictions using the trained network\"\"\"\n",
        "    z1 = np.dot(X_test, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "    return a2\n",
        "\n",
        "# ===== PART 7: TRAINING THE NETWORK =====\n",
        "\n",
        "print(\"\\n=== TRAINING NEURAL NETWORK ===\")\n",
        "print(\"Training started...\")\n",
        "\n",
        "# Calculate initial cost\n",
        "initial_predictions = predict(X)\n",
        "initial_cost = compute_cost(initial_predictions, y)\n",
        "print(f\"Initial cost: {initial_cost:.6f}\")\n",
        "\n",
        "# Train the network\n",
        "costs = full_training(X, y, epochs=2000)\n",
        "\n",
        "print(\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhGY6vE7ZjDU",
        "outputId": "5690d338-5186-4e1b-a625-b3b0a2cd85e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRAINING NEURAL NETWORK ===\n",
            "Training started...\n",
            "Initial cost: 0.261188\n",
            "Epoch 0, Cost: 0.261188\n",
            "Epoch 500, Cost: 0.244836\n",
            "Epoch 1000, Cost: 0.197630\n",
            "Epoch 1500, Cost: 0.093106\n",
            "Training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PART 8: EVALUATING RESULTS =====\n",
        "\n",
        "print(\"\\n=== EVALUATION RESULTS ===\")\n",
        "\n",
        "# Get final predictions\n",
        "final_predictions = predict(X)\n",
        "final_cost = compute_cost(final_predictions, y)\n",
        "\n",
        "print(f\"Final cost: {final_cost:.6f}\")\n",
        "print(f\"Cost improvement: {initial_cost - final_cost:.6f}\")\n",
        "\n",
        "# Calculate accuracy\n",
        "rounded_predictions = np.round(final_predictions)\n",
        "accuracy = np.mean(rounded_predictions == y) * 100\n",
        "print(f\"Accuracy: {accuracy:.1f}%\")\n",
        "\n",
        "# Show detailed results\n",
        "print(\"\\nDetailed Results:\")\n",
        "print(\"Input -> Predicted -> Target -> Correct?\")\n",
        "for i in range(len(X)):\n",
        "    pred = final_predictions[i, 0]\n",
        "    target = y[i, 0]\n",
        "    rounded_pred = rounded_predictions[i, 0]\n",
        "    correct = \"✓\" if rounded_pred == target else \"✗\"\n",
        "    print(f\"{X[i]} -> {pred:.3f} -> {target} -> {correct}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnqyGsSDc0L1",
        "outputId": "4a6674fc-082f-4884-b8ab-02c3fa4b553a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== EVALUATION RESULTS ===\n",
            "Final cost: 0.019204\n",
            "Cost improvement: 0.241984\n",
            "Accuracy: 100.0%\n",
            "\n",
            "Detailed Results:\n",
            "Input -> Predicted -> Target -> Correct?\n",
            "[0 0] -> 0.128 -> 0 -> ✓\n",
            "[0 1] -> 0.865 -> 1 -> ✓\n",
            "[1 0] -> 0.866 -> 1 -> ✓\n",
            "[1 1] -> 0.156 -> 0 -> ✓\n"
          ]
        }
      ]
    }
  ]
}